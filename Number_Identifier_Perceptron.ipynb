{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow #for showing the images if needed\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "1DC32D9qCegd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DO07neTX-Cyi"
      },
      "outputs": [],
      "source": [
        "# download the mnist dataset first\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# make the filter/mask for 0 and 1 from the dataset\n",
        "train_mask = (y_train == 0) | (y_train == 1) # | means or\n",
        "test_mask = (y_test == 0) | (y_test == 1)\n",
        "\n",
        "X_train, y_train = X_train[train_mask], y_train[train_mask] #filter them from the dataset now\n",
        "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
        "\n",
        "#flatten images as perceptron only takes 1D input\n",
        "X_train = X_train.reshape(X_train.shape[0], 28*28) #28*28 is for a 784 vector of images\n",
        "X_test  = X_test.reshape(X_test.shape[0], 28*28)\n",
        "\n",
        "#normalise\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDQvNXgxBGc5",
        "outputId": "2bc5f641-2a65-447a-a283-ddfb0f7c6c97"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12665, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, n_features, lr=0.01, n_epochs=10):\n",
        "        self.w = np.zeros(n_features) #weights\n",
        "        self.b = 0 #bias\n",
        "        self.lr = lr\n",
        "        self.n_epochs = n_epochs\n",
        "\n",
        "    def step(self, z):\n",
        "        return np.where(z >= 0, 1, 0)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.n_epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                z = np.dot(xi, self.w) + self.b\n",
        "                y_pred = self.step(z)\n",
        "                update = self.lr * (target - y_pred)\n",
        "                self.w += update * xi\n",
        "                self.b += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.step(np.dot(X, self.w) + self.b)"
      ],
      "metadata": {
        "id": "_1ewG8h4COJS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "model = Perceptron(n_features=X_train.shape[1], lr=0.01, n_epochs=10)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dEdKdxo4EdGM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.mean(y_hat == y_test)\n",
        "print(f\"Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nfDAkntFIDb",
        "outputId": "9715d845-2b5e-4e83-bd2d-4d4b8eee5251"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"img.png\", cv2.IMREAD_GRAYSCALE).flatten() / 255\n",
        "img = img.reshape(1, -1)\n",
        "y_hat_img = model.predict(img)\n",
        "print(\"Prediction for this image:\", y_hat_img[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "OVFto8S6J_xY",
        "outputId": "cef25b58-23fe-4a92-f92c-13c21a46c2b5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1x784>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAMQCAAAAADDHFD2AAAAW0lEQVR4Ae2TwQoAIAhDtf//6CSReXN5irAODXqTsUjkmaWtJLo6tp5LxDPeJg0+TjZx8HFyPtBQjBM0FOMDMz50kdX0ktuA9l74v2hk3hhUqOMzpvsOxfifrzeXzAA1lEXq7QAAAABJRU5ErkJggg==\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAMQAAEBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiilpKKKKKKKKKKKKKKKKKKKKKK//2Q==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for this image: 1\n"
          ]
        }
      ]
    }
  ]
}